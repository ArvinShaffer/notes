[TOC]

# Surface normal on surface
- The vector perpendicular to the tangent plane of the surface at a point P
- åœ¨ç‚¹ P å¤„å‚ç›´äºè¡¨é¢åˆ‡å¹³é¢çš„å‘é‡

- Applications
  - Segmentation / Clustering  åˆ†å‰²/èšç±»
  - Plane detection   å¹³é¢æ£€æµ‹
  - Point cloud feature for applications like Deep Learning   æ·±åº¦å­¦ä¹ ç­‰åº”ç”¨çš„ç‚¹äº‘åŠŸèƒ½

**How to compute**

- Surface normal on 3D point cloud  3D ç‚¹äº‘ä¸Šçš„è¡¨é¢æ³•çº¿
  1.Select a point P é€‰æ‹©ä¸€ä¸ªç‚¹ P
  2.Find the neighborhood that defines the surface æ‰¾åˆ°å®šä¹‰æ›²é¢çš„é‚»åŸŸ
  3.PCA
  4.Normal -> the least significant vector  æœ€ä¸é‡è¦çš„å‘é‡
  5.Curvature -> ratio between eigen values $ğœ†_3/(ğœ†_1 + ğœ†_2 + ğœ†_3)$ ç‰¹å¾å€¼ä¹‹é—´çš„æ¯”ç‡
- Intuitively it is obvious, can we prove it formally? ç›´è§‚ä¸Šå¾ˆæ˜æ˜¾ï¼Œæˆ‘ä»¬å¯ä»¥æ­£å¼è¯æ˜å—ï¼Ÿ



**Surface Normal Estimation â€“ Definition è¡¨é¢æ³•çº¿ä¼°è®¡ - å®šä¹‰**

- Problem Definition

- Denote data points as $x_i \in R^n, i = 1,2,\cdots,m$,   find a (hyper) plane,  that passes through a point c with normal vector n,  s.t. 

- å°†æ•°æ®ç‚¹è¡¨ç¤ºä¸º $x_i \in R^n, i = 1,2,\cdots,m$ï¼Œæ‰¾åˆ°ä¸€ä¸ªï¼ˆè¶…ï¼‰å¹³é¢ï¼Œè¯¥å¹³é¢é€šè¿‡æ³•å‘é‡ n, s.t. çš„ç‚¹ cã€‚

- $$
  \underset{c,n,\|n\|=1}{min} \sum_{i=1}^{m} ((x_i - c)^Tn)^2
  $$

![0014.hyperPlane](1301pclpics/0014.hyperPlane.png)

**Surface Normal Estimation â€“ Proof**

- Since c and n are independent variables, letâ€™s look at c first

- $$
  c^* = \underset{c}{arg\ min} \sum_{i=1}^m ((x_i - c)^T n)^2
  $$

- That means c* is the center of the data points

- $$
  \bar{x} = \frac{1}{m} \sum_{i=1}^m x_i \cdot
  $$

  ![0015.MeansOfc](1301pclpics/0015.MeansOfc.png)



- So we normalize the data points by its center, similar to what we did in PCA proof.

- æ‰€ä»¥æˆ‘ä»¬æŒ‰å…¶ä¸­å¿ƒå¯¹æ•°æ®ç‚¹è¿›è¡Œå½’ä¸€åŒ–ï¼Œç±»ä¼¼äºæˆ‘ä»¬åœ¨ PCA è¯æ˜ä¸­æ‰€åšçš„ã€‚

- $$
  \tilde{X} = [\tilde{x}_1, \cdots, \tilde{x}_m], \tilde{x}_i = x_i - \bar{x}, i = 1, \cdots, m
  $$

- Now the problem becomes,

- $$
  \underset{n \in R^n}{min}  \sum_{i=1}^m (\tilde{x}_i^T n)^2, s.t.:\|n\|_2 = 1
  $$



**What shall we do when there are noise?**

- 1.Select neighbors according to problem E.g. Radius based neighbors

  a.Radius larger -> normal estimation is smoother, but affected by irrelevant objects  æ­£å¸¸ä¼°è®¡æ›´å¹³æ»‘ï¼Œä½†å—ä¸ç›¸å…³ç‰©ä½“å½±å“
  b.Radius smaller -> normal estimation is sharper, but noisy  æ­£å¸¸ä¼°è®¡æ›´æ¸…æ™°ï¼Œä½†æœ‰å™ªéŸ³

- 2.Weighted based on other features

  a.Lidar intensity æ¿€å…‰é›·è¾¾å¼ºåº¦
  b.RGB values  RGB å€¼

- 3.RANSAC
  a.Lecture 4
- 4.Deep Learning!



**Weighted normal estimation**
$$
\underset{n \in R^n}{min} \sum_{i=1}^m w_i (x_i^T n)^2, s.t.:\| n\|_2 = 1  \\
W = \begin{bmatrix} w_1 & 0 & \cdots & 0 \\ 0 & w_2 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & w_m \end{bmatrix}
$$


**Deep Learning about Surface Normal**

- Predicting Depth, Surface Normals and Semantic Labels with a Common Multi-Scale Convolutional Architecture
- ä½¿ç”¨é€šç”¨å¤šå°ºåº¦å·ç§¯æ¶æ„é¢„æµ‹æ·±åº¦ã€è¡¨é¢æ³•çº¿å’Œè¯­ä¹‰æ ‡ç­¾
  - ICCV 2015
  - Joint estimation of depth and surface normal improves the depth result
  - ä½¿ç”¨é€šç”¨å¤šå°ºåº¦å·ç§¯æ¶æ„é¢„æµ‹æ·±åº¦ã€è¡¨é¢æ³•å‘é‡å’Œè¯­ä¹‰æ ‡ç­¾

![0016.DeepLearningSurfaceNormal](1301pclpics/0016.DeepLearningSurfaceNormal.png)

- Nesti-Net: Normal Estimation for Unstructured 3D Point Clouds using Convolutional Neural Networks
- Nesti-Netï¼šä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œå¯¹éç»“æ„åŒ– 3D ç‚¹äº‘è¿›è¡Œæ­£æ€ä¼°è®¡
  - CVPR 2019

![0017.Nesti-Net](1301pclpics/0017.Nesti-Net.png)



# Filters

- Noise removal  é™å™ª
  - Radius Outlier Removal  åŠå¾„å¼‚å¸¸å€¼å»é™¤
  - Statistical Outlier Removal   ç»Ÿè®¡å¼‚å¸¸å€¼å»é™¤
- Downsampling  ä¸‹é‡‡æ ·
  - Voxel Grid Downsampling  ä½“ç´ ç½‘æ ¼ä¸‹é‡‡æ ·
    - Exact / Approximated ç²¾ç¡®/è¿‘ä¼¼
    - Centroid / Random Selection è´¨å¿ƒ/éšæœºé€‰æ‹©
  - Farthest Point Sampling æœ€è¿œç‚¹é‡‡æ ·
  - Normal Space Sampling  æ­£å¸¸ç©ºé—´é‡‡æ ·
- Upsampling / Smoothing / Noise Removal  ä¸Šé‡‡æ ·/å¹³æ»‘/é™å™ª
  - Bilateral Filter åŒè¾¹è¿‡æ»¤å™¨

![0018.Filters](1301pclpics/0018.Filters.png)



# Noise removal  é™å™ª

## Radius Outlier Removal åŠå¾„å¼‚å¸¸å€¼å»é™¤

- 1.For each point, find a radius = r neighborhood å¯¹äºæ¯ä¸ªç‚¹ï¼Œæ‰¾åˆ°ä¸€ä¸ªåŠå¾„=rçš„é‚»åŸŸ
- 2.If number of neighbor $k < k^*$ , remove the point å¦‚æœé‚»å±…æ•° $k < k^*$ ï¼Œåˆ™åˆ é™¤è¯¥ç‚¹

![0019.RadiusOutlier](1301pclpics/0019.RadiusOutlier.png)



## Statistical Outlier Removal ç»Ÿè®¡å¼‚å¸¸å€¼å»é™¤

- 1.For each point, find a neighborhood  å¯¹äºæ¯ä¸ªç‚¹ï¼Œæ‰¾åˆ°ä¸€ä¸ªé‚»åŸŸ

- 2.Compute its distance to its neighbors  $d_{ij}, i = [1,\cdots, m], j = [1,\cdots,k]$  è®¡ç®—å®ƒåˆ°é‚»å±…çš„è·ç¦»

- 3.Model the distances by Gaussian distribution $d \sim N(\mu, \sigma)$  é€šè¿‡é«˜æ–¯åˆ†å¸ƒå¯¹è·ç¦»å»ºæ¨¡ \

- $$
  \mu = \frac{1}{nk} \sum_{i=1}^m \sum_{j=1}^k d_{ij}, \quad \sigma = \sqrt{\frac{1}{nk} \sum_{i=1}^m \sum_{j=1}^k (d_{ij} - \mu)^2}
  $$

- 4.For each point, compute its mean distance to its neighbors å¯¹äºæ¯ä¸ªç‚¹ï¼Œè®¡ç®—å®ƒåˆ°é‚»å±…çš„å¹³å‡è·ç¦»

- 5.Remove the point, if the mean distance is outside some confidence according to the Gaussian distribution åˆ é™¤ç‚¹ï¼Œå¦‚æœæ ¹æ®é«˜æ–¯åˆ†å¸ƒï¼Œå¹³å‡è·ç¦»è¶…å‡ºä¸€äº›ç½®ä¿¡åº¦

  E.g. Remove if

- $$
  \sum_{j=1}^k d_{ij} > \mu + 3\sigma \ or \  \sum_{j=1}^k d_{ij} < \mu - 3\sigma
  $$

![0020.StatisticalOutlierRemoval](1301pclpics/0020.StatisticalOutlierRemoval.png)



# Downsampling ä¸‹é‡‡æ ·

## Voxel Grid Downsampling

- 1.Build a voxel grid that contains the point cloud  æ„å»ºåŒ…å«ç‚¹äº‘çš„ä½“ç´ ç½‘æ ¼
- 2.Take one point in each cell åœ¨æ¯ä¸ªå•å…ƒæ ¼å–ä¸€åˆ†

- Q1, how to â€œtake one pointâ€?
- Q2, how to make it efficient?

![0021.VoxelGridDownsampling](1301pclpics/0021.VoxelGridDownsampling.png)



**How to â€œtake one pointâ€ from a cell in the grid? å¦‚ä½•ä»ç½‘æ ¼ä¸­çš„å•å…ƒæ ¼ä¸­â€œå–ä¸€åˆ†â€ï¼Ÿ**

- 1.Centroid è´¨å¿ƒ
  - a.For coordinates, compute the average in the cell å¯¹äºåæ ‡ï¼Œè®¡ç®—å•å…ƒæ ¼ä¸­çš„å¹³å‡å€¼
  - b.For other attributes, voting / average å¯¹äºå…¶ä»–å±æ€§ï¼ŒæŠ•ç¥¨/å¹³å‡
  - c.More accurate but slower æ›´å‡†ç¡®ä½†æ›´æ…¢
- 2.Random select éšæœºé€‰æ‹©
  - a.Randomly select a point in the cell  éšæœºé€‰æ‹©å•å…ƒæ ¼ä¸­çš„ä¸€ä¸ªç‚¹
  - b.Less accurate but faster  ä¸å¤ªå‡†ç¡®ä½†é€Ÿåº¦æ›´å¿«

### Exact

- 1.Compute the min or max of the point set ${p_1,p_2, \cdots,p_N}$è®¡ç®—ç‚¹é›†çš„æœ€å°å€¼æˆ–æœ€å¤§å€¼

- $$
  x_{max} = max(x_1,x_2,\cdots, x_N), \  x_{min} = min(x_1,x_2,\cdots, x_N), y_{max} = \cdots \cdots
  $$

- 2.Determine the voxel grid size $ğ‘Ÿ$ ç¡®å®šä½“ç´ ç½‘æ ¼å¤§å° $ğ‘Ÿ$

- 3.Compute the dimension of the voxel grid è®¡ç®—ä½“ç´ ç½‘æ ¼çš„ç»´åº¦

- $$
  D_x = (x_{max} - x_{min}) / r \\
  D_y = (y_{max} - y_{min}) / r \\
  D_z = (z_{max} - z_{min}) / r
  $$

- 4.Compute voxel index for each point è®¡ç®—æ¯ä¸ªç‚¹çš„ä½“ç´ æŒ‡æ•°

- $$
  h_x = \left \lfloor (x - x_{min}) / r \right \rfloor \\
  h_y = \left \lfloor (y - y_{min} / r  \right \rfloor \\
  h_z = \left \lfloor (z - z_{min} / r \right \rfloor \\
  h = h_x + h_y * D_x + h_z * D_x * D_y
  $$

- 5.Sort the points according to the index in Step 4 æ ¹æ®æ­¥éª¤4ä¸­çš„ç´¢å¼•å¯¹ç‚¹è¿›è¡Œæ’åº

- 6.Iterate the sorted points, select points according to Centroid / Random method 0, 0, 0, 0, 3, 3, 3, 8, 8, 8, 8, 8, 8, 8, 8, â€¦â€¦ è¿­ä»£æ’åºåçš„ç‚¹ï¼Œæ ¹æ®è´¨å¿ƒ/éšæœºæ–¹æ³•é€‰æ‹©ç‚¹



**Int32 overflow!**

- Example, 3D lidar in autonomous driving. Detection range 200m, voxel grid resolution r=0.05m, assume we crop z to be [-10, 10] 
- ä¾‹å¦‚ï¼Œè‡ªåŠ¨é©¾é©¶ä¸­çš„ 3D æ¿€å…‰é›·è¾¾ã€‚ æ£€æµ‹èŒƒå›´200mï¼Œä½“ç´ ç½‘æ ¼åˆ†è¾¨ç‡r=0.05mï¼Œå‡è®¾æˆ‘ä»¬è£å‰ªzä¸º[-10, 10]
- Dimension of the voxel grid: $(20/0.05) * (400/0.05) * (400/0.05)=2.56 \times 10^{10}$
- $2^{32} = 4.3 \times 10^9 < 2.56 \times 10^{10}$



**Strict Weak Ordering!ä¸¥æ ¼å¼±åº** 

- In cpp, the sort function in <algorithm> supports customized comparator
- åœ¨cppä¸­ï¼Œ<algorithm>ä¸­çš„sortå‡½æ•°æ”¯æŒè‡ªå®šä¹‰æ¯”è¾ƒå™¨
- However, the comparator should follow the strict weak ordering:
- ä½†æ˜¯ï¼Œæ¯”è¾ƒå™¨åº”éµå¾ªä¸¥æ ¼çš„å¼±æ’åºï¼š

![0022.StrictWeakOrdering](1301pclpics/0022.StrictWeakOrdering.png)

- In the voxel grid downsampling setting, the sorting comparator should be a.index < b.index, instead of a.index <= b.index
- åœ¨ä½“ç´ ç½‘æ ¼ä¸‹é‡‡æ ·è®¾ç½®ä¸­ï¼Œæ’åºæ¯”è¾ƒå™¨åº”è¯¥æ˜¯a.index < b.indexï¼Œè€Œä¸æ˜¯a.index <= b.index
- Otherwise this is undefined behavior that may lead to segmentation fault
- å¦åˆ™è¿™æ˜¯å¯èƒ½å¯¼è‡´åˆ†æ®µé”™è¯¯çš„æœªå®šä¹‰è¡Œä¸º



### Approximated

- Exact voxel grid downsampling requires sorting O(N*log(N))
- ç²¾ç¡®çš„ä½“ç´ ç½‘æ ¼ä¸‹é‡‡æ ·éœ€è¦æ’åº O(N*log(N))
- However, in most cases, the voxel is SPARSE
- ç„¶è€Œï¼Œåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œä½“ç´ æ˜¯ç¨€ç–çš„
- Image we have N=10000 points, we know after downsamling the number M < 100. (E.g, 95)
- å›¾åƒæˆ‘ä»¬æœ‰ N=10000 ä¸ªç‚¹ï¼Œæˆ‘ä»¬çŸ¥é“åœ¨å¯¹æ•°å­— M < 100 è¿›è¡Œä¸‹é‡‡æ ·åã€‚ï¼ˆä¾‹å¦‚ï¼Œ95ï¼‰
- Can we have a magic function, that maps the 10000 points into the 100 containers?
- æˆ‘ä»¬å¯ä»¥æœ‰ä¸€ä¸ªé­”æ³•å‡½æ•°ï¼Œå°† 10000 ä¸ªç‚¹æ˜ å°„åˆ° 100 ä¸ªå®¹å™¨ä¸­å—ï¼Ÿ
- Finally we just extract one point from the 100 containers. Ideally there will be 95 non-empty containers, and 5 empty.
- æœ€åæˆ‘ä»¬åªä» 100 ä¸ªå®¹å™¨ä¸­æå–ä¸€ä¸ªç‚¹ã€‚ ç†æƒ³æƒ…å†µä¸‹ï¼Œå°†æœ‰ 95 ä¸ªéç©ºå®¹å™¨å’Œ 5 ä¸ªç©ºå®¹å™¨ã€‚

**Hash Table!**

- 1.Compute the min / max of each coordinate
- 2.Determine the voxel grid size r
- 3.Compute the dimension of the voxel grid
- 4.Compute voxel index for each point è®¡ç®—æ¯ä¸ªç‚¹çš„ä½“ç´ æŒ‡æ•°
- 5.Use a hash function to map each point to a container $G_i$ in  $\left \{G_1, G_2 , \cdots , G_M \right \}$ ä½¿ç”¨æ•£åˆ—å‡½æ•°å°†æ¯ä¸ªç‚¹æ˜ å°„åˆ°$\left \{G_1, G_2 , \cdots , G_M \right \}$ä¸­çš„å®¹å™¨$G_i$
- 6.Iterate   $\left \{G_1, G_2 , \cdots , G_M \right \}$ and get M point!

**That hash function is**
$$
hash(h_x, h_y, h_z) : \mathbb{R}^3 \rightarrow \mathbb{R} \\
E.g., \ hash(h_x, h_y, h_z) = (h_x + h_y * D_x + h_z * D_x * D_y) \ \% \ container\_size
$$


- The hash function is not magic, not perfect!

  - Different voxel will map into the same value ä¸åŒçš„ä½“ç´ å°†æ˜ å°„åˆ°ç›¸åŒçš„å€¼

  - $$
    hash(h_x, h_y, h_z) = hash(h_x', h_y', h_z'), h_x \neq h_x' \ or \ h_y \neq h_y' \ or \ h_z \neq h_z'
    $$

  - Consequence: The 10000 points should fill in 95 containers, but in fact fill only 80. You are missing 15 points! 

  - ç»“æœï¼š10000ç‚¹åº”è¯¥å¡«æ»¡95ä¸ªå®¹å™¨ï¼Œä½†å®é™…ä¸Šåªå¡«äº†80ä¸ªã€‚ä½ å°‘äº†15ä¸ªç‚¹ï¼

- This is called conflict in hash table

- If you find a conflict, what do you do?
  - a.Select a point from the container
  - b.Empty that container



## Farthest Point Sampling (FPS)

- Randomly choose a point to be the first FPS point éšæœºé€‰æ‹©ä¸€ä¸ªç‚¹ä½œä¸ºç¬¬ä¸€ä¸ªFPSç‚¹
- Iterate until we get the desired number of points
  - a.For each point in the original point cloud, compute its distance to the nearest FPS point 
  - å¯¹äºåŸå§‹ç‚¹äº‘ä¸­çš„æ¯ä¸ªç‚¹ï¼Œè®¡ç®—å®ƒåˆ°æœ€è¿‘çš„FPSç‚¹çš„è·ç¦»
  - b.Choose the point with the largest value, add to FPS set
  - é€‰æ‹©å€¼æœ€å¤§çš„ç‚¹ï¼ŒåŠ å…¥FPSé›†

![0023.FarthestPointSampling](1301pclpics/0023.FarthestPointSampling.png)

## Normal Space Sampling (NSS)

- Used in Iterative Closest Point
  - 1.Construct a set of buckets in the normal space åœ¨æ™®é€šç©ºé—´æ„é€ ä¸€ç»„æ¡¶
  - 2.Put all points into bucket according to the surface normals æ ¹æ®è¡¨é¢æ³•çº¿å°†æ‰€æœ‰ç‚¹æ”¾å…¥æ¡¶ä¸­
  - 3.Uniformly pick points from all buckets until we have the desired number of points ç»Ÿä¸€ä»æ‰€æœ‰æ¡¶ä¸­é€‰å–ç‚¹ï¼Œç›´åˆ°æˆ‘ä»¬å¾—åˆ°æ‰€éœ€çš„ç‚¹æ•°

![0024.NormalSpaceSampling](1301pclpics/0024.NormalSpaceSampling.png)

## Learning to Sample

![0025.LearningToSample](1301pclpics/0025.LearningToSample.png)

![0026.LearningToSample1](1301pclpics/0026.LearningToSample1.png)

![0027.LearningToSample2](1301pclpics/0027.LearningToSample2.png)

- The Learning to Sample is targeted to some specific task, e.g., Classification
- é‡‡æ ·å­¦ä¹ é’ˆå¯¹æŸäº›ç‰¹å®šä»»åŠ¡ï¼Œä¾‹å¦‚åˆ†ç±»
- Semantics based downsampling instead of pure geometric based.
- åŸºäºè¯­ä¹‰çš„ä¸‹é‡‡æ ·è€Œä¸æ˜¯åŸºäºçº¯å‡ ä½•çš„ã€‚

![0028.LearningToSample3](1301pclpics/0028.LearningToSample3.png)

- NRE:
  - Normalized Reconstructed Error å½’ä¸€åŒ–é‡æ„é”™è¯¯
- The output of S-Net is visually similar to that of FPS S-Net çš„è¾“å‡ºåœ¨è§†è§‰ä¸Šä¸ FPS ç›¸ä¼¼
  - This is expected because of Chamfer loss è¿™æ˜¯é¢„æœŸçš„ï¼Œå› ä¸ºå€’è§’æŸå¤±

![0029.LearningToSample4](1301pclpics/0029.LearningToSample4.png)

# Upsampling/Smoothing/Noise Removal ä¸Šé‡‡æ ·/å¹³æ»‘/é™å™ª

**Bilateral Filter â€“ Gaussian Filter**

![0030.BilateralFilter](1301pclpics/0030.BilateralFilter.png)

**Edge Preserving Blurring**

![0031.EdgePreservingBluring](1301pclpics/0031.EdgePreservingBluring.png)

## Bilateral Filter åŒè¾¹è¿‡æ»¤å™¨

- Given image I, for each pixel p, find its neighbor S.

- each pair (p, q)

  - Compute distance weight $ğº_{\sigma_s}$ intensity weight $ğº_{\sigma_r}$

  - $$
    ğº_{\sigma} (x) = \frac{1}{2\pi \sigma^2} exp(- \frac{x^2}{2 \sigma^2})
    $$

  - Apply Bilateral Filter to get intensity of pixel p

  - $$
    BF[I]_p = \frac{1}{W_p} \sum_{q \in S} G_{\sigma_s}(\| p-q \|) G_{\sigma_r}(I_p - I_q)I_q \\
    W_p = \sum_{q \in S} G_{\sigma_s} (\|p - q\|) G_{\sigma_r}(I_p - I_q)
    $$

![0032.BilateralFilter](1301pclpics/0032.BilateralFilter.png)

![0033.BilateralFilter](1301pclpics/0033.BilateralFilter.png)

# Compulsory

- 1.Build dataset
  a.Download ModelNet40 dataset
  b.Select one point cloud from each category
- 2.Perform PCA for the 40 objects, visualize it.
- 3.Perform surface normal estimation for each point of each object, visualize it.å¯¹æ¯ä¸ªå¯¹è±¡çš„æ¯ä¸ªç‚¹è¿›è¡Œè¡¨é¢æ³•çº¿ä¼°è®¡ï¼Œå¹¶å°†å…¶å¯è§†åŒ–ã€‚
- 4.Downsample each object using voxel grid downsampling (exact, both centroid & random). Visualize the results.
- 5.Write your own code, DO NOT call apis (PCL, open3d, etc.) except for visualization.ä½¿ç”¨ä½“ç´ ç½‘æ ¼ä¸‹é‡‡æ ·ï¼ˆç²¾ç¡®ï¼Œè´¨å¿ƒå’Œéšæœºï¼‰å¯¹æ¯ä¸ªå¯¹è±¡è¿›è¡Œä¸‹é‡‡æ ·ã€‚ å¯è§†åŒ–ç»“æœã€‚

- KITTI depth dataset
  - http://www.cvlibs.net/datasets/kitti/eval_depth_all.php
  - Download and get familiar KITTI dataset
- Perform depth upsampling / completion for the validation dataset å¯¹éªŒè¯æ•°æ®é›†æ‰§è¡Œæ·±åº¦ä¸Šé‡‡æ ·/å®Œæˆ
  - Use whatever method you want, except Deep Learning method. ä½¿ç”¨ä»»ä½•ä½ æƒ³è¦çš„æ–¹æ³•ï¼Œæ·±åº¦å­¦ä¹ æ–¹æ³•é™¤å¤–ã€‚
- Evaluate the result using the evaluation code provided in the kitti-depth development kit.
- ä½¿ç”¨ kitti-depth å¼€å‘å¥—ä»¶ä¸­æä¾›çš„è¯„ä¼°ä»£ç è¯„ä¼°ç»“æœã€‚

